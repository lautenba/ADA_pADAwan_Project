{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "#from html.parser import HTMLParser\n",
    "# import website_func.py to use its functions\n",
    "from website_func import *\n",
    "#reload every module each time\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some quick analysis of the data\n",
    "We received a data set of .html file containing the website content of recipes.\n",
    "We wanted to sort them by website, in order to, more easily, find a pattern among them. This will enable us to do the \"scraping\" of the pages. First we thought about moving the files in a folder corresponding to their website, but it would be a waste of time and a big computational effort. Thus, we came up with a (probably) faster solution : we could simply write the name of the file within its corresponding website folder. By inspecting the files, we saw that the first line was always containing a comment with the name of the file and the complete website. Using readlines and split, we could easily retrieve the name of the website.\n",
    "\n",
    "We launched this process, but an alarm appeared describing a Trojan virus in the file \"1c2cb6f0df04cf5a9d0baa116c6aa7bb.html\". \n",
    "We had then to quarantine or mabye remove the file, as we have quite enough\n",
    "By doing so, we remarked the file \"msg.log\" that could help us into fastering the processus as its content is formed of the name of the file together with its website. [SHOW] We obserbed that occasionally a line containing other info that the content we want can appear. We need to ignore this\n",
    "Also we noticed there are no file extensions other than .html and .log. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished sorting the files\n"
     ]
    }
   ],
   "source": [
    "retrieve_website_from_log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recipePages\\msg.log\n"
     ]
    }
   ],
   "source": [
    "# We can find in the folder that, excepted the html files, there is only the log\n",
    "\n",
    "# Get all filenames (i.e. path) that are in recipePages folder \n",
    "pathlist = Path(\"recipePages/\").glob('**/*')\n",
    "i = 0\n",
    "for path in pathlist:\n",
    "     # because path is object not string\n",
    "    path_in_str = str(path)\n",
    "    if not path_in_str.endswith(\".html\"):\n",
    "        print(path_in_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:conda-ada] *",
   "language": "python",
   "name": "conda-env-conda-ada-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
